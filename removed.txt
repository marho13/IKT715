    def entropyCalc(self, featureNum):
        featureEntropy = []
        split, num = self.train(featureNum)
        for a in range(len(split)):
            entro = []
            for b in range(len(split[a])):
                entro.append([])
                for c in range(len(split[a][b])):
                    for d in range(len(split[a][b])):
                        if c != d:
                            if split[a][b][c] != 0:
                                numClass = len(self.training[c]) + len(self.training[d])
                                floaty = split[a][b][c]/(numClass)
                                logy = math.log(floaty, 2)
                                rem = (numClass-split[a][b][c])/numClass
                                entro[-1].append(-(floaty*logy)-(rem*math.log(rem, 2)))
                            else:
                                entro[-1].append(0)
            featureEntropy.append(entro)

        return featureEntropy